{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    ">This module has functions to generate the burned areas predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.vision import *\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "from banet.core import *\n",
    "from banet.models import BA_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def open_mat(fn, *args, **kwargs):\n",
    "    data = sio.loadmat(fn)\n",
    "    data = np.array([data[r] for r in ['Red', 'NIR', 'MIR', 'FRP']])\n",
    "    data[np.isnan(data)] = 0\n",
    "    data[-1, ...] = np.log1p(data[-1,...])\n",
    "    data[np.isnan(data)] = 0\n",
    "    return data\n",
    "\n",
    "def crop(im, r, c, size=128): \n",
    "    '''\n",
    "    crop image into a square of size sz, \n",
    "    '''\n",
    "    sz = size\n",
    "    out_sz = (sz, sz, im.shape[-1])\n",
    "    rs,cs,hs = im.shape\n",
    "    tile = np.zeros(out_sz)\n",
    "    if (r+sz > rs) and (c+sz > cs):\n",
    "        tile[:rs-r, :cs-c, :] = im[r:, c:, :]\n",
    "    elif (r+sz > rs):\n",
    "        tile[:rs-r, :, :] = im[r:, c:c+sz, :]\n",
    "    elif (c+sz > cs):\n",
    "        tile[:, :cs-c, :] = im[r:r+sz ,c:, :]\n",
    "    else:\n",
    "        tile[...] = im[r:r+sz, c:c+sz, :]\n",
    "    return tile\n",
    "\n",
    "def image2tiles(x, step=100):\n",
    "    tiles = []\n",
    "    rr, cc, _ = x.shape\n",
    "    for c in range(0, cc-1, step):\n",
    "        for r in range(0, rr-1, step):\n",
    "            img = crop(x, r, c)\n",
    "            tiles.append(img)\n",
    "    return np.array(tiles)\n",
    "                \n",
    "def tiles2image(tiles, image_size, size=128, step=100):\n",
    "    rr, cc, = image_size\n",
    "    sz = size\n",
    "    im = np.zeros(image_size)\n",
    "    indicator = np.zeros_like(im).astype(float)\n",
    "    k = 0\n",
    "    for c in range(0, cc-1, step):\n",
    "        for r in range(0, rr-1, step):\n",
    "            if (r+sz > rr) and (c+sz > cc):\n",
    "                im[r:, c:] += tiles[k][:rr-r, :cc-c]\n",
    "                indicator[r:, c:] += 1\n",
    "            elif (r+sz > rr):\n",
    "                im[r:, c:c+sz] += tiles[k][:rr-r, :] \n",
    "                indicator[r:, c:c+sz] += 1\n",
    "            elif (c+sz > cc):\n",
    "                im[r:r+sz ,c:] += tiles[k][:, :cc-c]\n",
    "                indicator[r:r+sz, c:] += 1\n",
    "            else:\n",
    "                im[r:r+sz, c:c+sz] += tiles[k]\n",
    "                indicator[r:r+sz, c:c+sz] += 1\n",
    "            k += 1\n",
    "    im /= indicator\n",
    "    return im\n",
    "\n",
    "def get_preds(tiles, model, weights=None):\n",
    "    if weights is not None:\n",
    "        model.load_state_dict(weights)\n",
    "    mu = tensor([0.2349, 0.3548, 0.1128, 0.0016]).view(1,4,1,1,1)\n",
    "    std = tensor([0.1879, 0.1660, 0.0547, 0.0776]).view(1,4,1,1,1)\n",
    "    with torch.no_grad():\n",
    "        data = []\n",
    "        for x in tqdm(tiles):\n",
    "            model.eval().cuda()\n",
    "            x = (x[None]-mu)/std\n",
    "            out = model(x.cuda()).sigmoid().float()\n",
    "            data.append(out.cpu().squeeze().numpy())\n",
    "    return np.array(data)\n",
    "\n",
    "def predict_one(iop, times, weights_files, region, threshold=0.5):\n",
    "    fname = lambda t : iop.src/f'{region}/VIIRS750{region}_{t.strftime(\"%Y%m%d\")}.mat'\n",
    "    files = [fname(t) for t in times]\n",
    "    im_size = open_mat(files[0]).shape[1:]\n",
    "    tiles = []\n",
    "    print('Loading data and generating tiles:')\n",
    "    for file in tqdm(files):\n",
    "        try:\n",
    "            s = image2tiles(open_mat(file).transpose((1,2,0))).transpose((0,3,1,2))\n",
    "        except:\n",
    "            warn(f'No data for {file}')\n",
    "            s = np.zeros_like(s)\n",
    "        tiles.append(s)\n",
    "    tiles = np.array(tiles).transpose((1, 2, 0, 3, 4))\n",
    "    tiles = torch.from_numpy(tiles).float()\n",
    "    preds_ens = []\n",
    "    for wf in weights_files:\n",
    "        weights = torch.load(wf)['model']\n",
    "        print(f'Generating model predictions for {wf}:')\n",
    "        preds = get_preds(tiles, model=BA_Net(4, 1, 64), weights=weights)\n",
    "        preds = np.array([tiles2image(preds[:,i], im_size) for i in range(preds.shape[1])])\n",
    "        preds_ens.append(preds)\n",
    "    preds = np.array(preds_ens).mean(0)\n",
    "    return preds\n",
    "\n",
    "def predict_month(iop, time, weight_files, region, threshold=0.5, save=True):\n",
    "    time_start = pd.Timestamp((time - pd.Timedelta(days=30)).strftime('%Y-%m-15')) # Day 15, previous month\n",
    "    times = pd.date_range(time_start, periods=64, freq='D')\n",
    "    preds = predict_one(iop, times, weight_files, region, threshold=threshold)\n",
    "    assert preds.shape[0] == len(times)\n",
    "    preds = preds[times.month == time.month]\n",
    "    ba = preds.sum(0)\n",
    "    bd = preds.argmax(0)\n",
    "    doy = np.asarray(pd.DatetimeIndex(times).dayofyear)\n",
    "    bd = doy[bd].astype(float)\n",
    "    bd[bd==doy[0]] = np.nan\n",
    "    bd[ba<threshold] = np.nan\n",
    "    ba[ba<threshold] = np.nan\n",
    "    ba[ba>1] = 1\n",
    "    if not save: return ba, bd\n",
    "    tstr = time.strftime('%Y%m')\n",
    "    sio.savemat(iop.dst/f'ba_{region}_{tstr}.mat', {'burned': ba, 'date': bd}, do_compression=True)\n",
    "\n",
    "def predict_nrt(iop, time, weights_files, region, threshold=0.5, save=True):\n",
    "    times = pd.date_range(time-pd.Timedelta(days=63), time, freq='D') \n",
    "    preds = predict_one(iop, times, weight_files, region, threshold=threshold)\n",
    "    assert preds.shape[0] == len(times)\n",
    "    ba = preds.sum(0)\n",
    "    bd = preds.argmax(0)\n",
    "    doy = np.asarray(pd.DatetimeIndex(times).dayofyear)\n",
    "    bd = doy[bd].astype(float)\n",
    "    bd[bd==doy[0]] = np.nan\n",
    "    bd[ba<threshold] = np.nan\n",
    "    ba[ba<threshold] = np.nan\n",
    "    ba[ba>1] = 1\n",
    "    if not save: return ba, bd\n",
    "    tstr = time.strftime('%Y%m%d')\n",
    "    sio.savemat(iop.dst/f'ba_{tstr}.mat', {'burned': ba, 'date': bd}, do_compression=True)\n",
    "\n",
    "def split_mask(mask, thr=0.5, thr_obj=1):\n",
    "    labled, n_objs = ndimage.label(mask > thr)\n",
    "    result = []\n",
    "    for i in range(n_objs):\n",
    "        obj = (labled == i + 1).astype(int)\n",
    "        if (obj.sum() > thr_obj): result.append(obj)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_geo.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_models.ipynb.\n",
      "Converted 04_predict.ipynb.\n",
      "Converted 06_cli.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fastai_dev)",
   "language": "python",
   "name": "fastai_dev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
