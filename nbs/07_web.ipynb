{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web\n",
    ">This module contain functions to process the model outputs for web applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from pathlib import Path\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import pdb\n",
    "import shapely\n",
    "from IPython.core.debugger import set_trace\n",
    "from shapely.geometry import Polygon\n",
    "from banet.core import *\n",
    "from banet.geo import  *\n",
    "from banet.predict import split_mask\n",
    "Path.ls = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ba_split(io_path:InOutPath, region:Region, threshold=0.5, min_size=1, keys=['burned', 'date']):\n",
    "    \"Computes burned areas shapefiles.\"\n",
    "    files = sorted(io_path.src.ls())\n",
    "    print(f'Processing {files[-1]}')\n",
    "    data = sio.loadmat(files[-1])\n",
    "    fires = split_mask((data[keys[0]]>=threshold).astype(np.uint8), thr_obj=min_size)\n",
    "    \n",
    "    times = pd.DatetimeIndex([pd.Timestamp(o) for o in data['times']])\n",
    "    doy = times.dayofyear.values.astype(int)\n",
    "\n",
    "    data[keys[1]][np.isnan(data[keys[1]])] = 0\n",
    "    data[keys[1]] = doy[data[keys[1]].astype(int)]\n",
    "    data[keys[1]] = data[keys[1]].astype(np.float16)\n",
    "    data[keys[1]][data[keys[1]]==doy[0]] = np.nan\n",
    "\n",
    "    gpd = gp.GeoDataFrame()\n",
    "    for fire in tqdm(fires):\n",
    "        dates = data[keys[1]].copy()\n",
    "        dates[fire==0] = np.nan\n",
    "        start_date = np.nanmin(dates)\n",
    "        end_date = np.nanmax(dates)\n",
    "        geoms = list({'properties': {'raster_val': v}, 'geometry': s}\n",
    "            for i, (s, v) in enumerate(rasterio.features.shapes(fire.astype(np.uint8), transform=region.transform))\n",
    "        )\n",
    "        g0 = gp.GeoDataFrame.from_features(geoms, crs={'init' :'epsg:4326'})\n",
    "        g0['start'] = start_date.astype(int)\n",
    "        g0['end'] = end_date.astype(int)\n",
    "        gpd = pd.concat((gpd, g0), axis=0)\n",
    "\n",
    "    gpd = gpd.loc[gpd.raster_val==1.0].reset_index(drop=True)\n",
    "    gpd = gp.GeoDataFrame(gpd, crs={'init' :'epsg:4326'})\n",
    "    gpd['area'] = (gpd.to_crs(epsg=25830).area.values*0.0001).astype(int) # TODO: EPGS for other regions\n",
    "    gpd = gpd.drop('raster_val', axis=1)\n",
    "    return gpd, data, fires\n",
    "\n",
    "def fires2raster(path_save, fires, data, region:Region, keys=['burned', 'date']):\n",
    "    \"Saves raster files for individual fires.\"\n",
    "    for i, f in enumerate(fires):\n",
    "        args = np.argwhere(f>0)\n",
    "        lon, lat = region.coords()\n",
    "        (rmin, cmin), (rmax, cmax) = args.min(0), args.max(0)\n",
    "        rmax += 1\n",
    "        cmax += 1\n",
    "        lat_r = lat[rmin-1:rmax+1]\n",
    "        lon_r = lon[cmin-1:cmax+1]\n",
    "        tfm = rasterio.Affine(region.pixel_size, 0, lon_r.min(), 0, -region.pixel_size, lat_r.max())\n",
    "        burned_r = data[keys[0]][rmin-1:rmax+1, cmin-1:cmax+1].copy().astype(np.float16)\n",
    "        date_r =  data[keys[1]][rmin-1:rmax+1, cmin-1:cmax+1].copy().astype(np.float16)\n",
    "        burned_r[f[rmin-1:rmax+1, cmin-1:cmax+1]==0] = np.nan\n",
    "        date_r[f[rmin-1:rmax+1, cmin-1:cmax+1]==0] = np.nan\n",
    "\n",
    "        burned_r = burned_r*255\n",
    "        burned_r[np.isnan(burned_r)] = 0\n",
    "        burned_r = burned_r.astype(np.uint16)\n",
    "        date_r[np.isnan(date_r)] = 0\n",
    "        date_r = date_r.astype(np.uint16)\n",
    "        raster = np.array((burned_r, date_r))\n",
    "\n",
    "        meta = {\n",
    "            'driver': 'GTiff', \n",
    "            'dtype': 'uint16', \n",
    "            'nodata': None, \n",
    "            'width': burned_r.shape[1], \n",
    "            'height': burned_r.shape[0], \n",
    "            'count': 2, \n",
    "            'crs': rasterio.crs.CRS.from_epsg(4326), \n",
    "            'transform': tfm\n",
    "        }\n",
    "\n",
    "        with rasterio.open(path_save/f'ba_{i}.tif', 'w', **meta) as dst:\n",
    "            dst.write(raster)\n",
    "    \n",
    "def out2raster(iop:InOutPath, region:Region, keys=['burned', 'date']):\n",
    "    \"Saves raster files for last output.\"\n",
    "    file = sorted(iop.src.ls())[-1]\n",
    "    print(f'Processing {file}')\n",
    "    data = sio.loadmat(file)\n",
    "    \n",
    "    lon, lat = region.coords()\n",
    "    burned_r = data[keys[0]]\n",
    "    date_r =  data[keys[1]]\n",
    "    burned_r = burned_r*255\n",
    "    burned_r[np.isnan(burned_r)] = 0\n",
    "    burned_r = burned_r.astype(np.uint16)\n",
    "    date_r[np.isnan(date_r)] = 0\n",
    "    date_r = date_r.astype(np.uint16)\n",
    "    raster = np.array((burned_r, date_r))\n",
    "\n",
    "    meta = {\n",
    "        'driver': 'GTiff', \n",
    "        'dtype': 'uint16', \n",
    "        'nodata': None, \n",
    "        'width': burned_r.shape[1], \n",
    "        'height': burned_r.shape[0], \n",
    "        'count': 2, \n",
    "        'crs': rasterio.crs.CRS.from_epsg(4326), \n",
    "        'transform': region.transform\n",
    "    }\n",
    "\n",
    "    with rasterio.open(iop.dst/f'{file.stem}.tif', 'w', **meta) as dst:\n",
    "        dst.write(raster)\n",
    "    \n",
    "def process_last(iop:InOutPath, region:Region, filter_region:Polygon, threshold=0.5, \n",
    "                 min_size=1, keys=['burned', 'date']):\n",
    "    df, data, fires = ba_split(iop, region, min_size=min_size, threshold=threshold, keys=keys)\n",
    "    df = df.loc[df.within(filter_region)]\n",
    "    fires = np.array(fires, dtype=np.uint16)\n",
    "    fires = fires[df.index.values.reshape(-1)]\n",
    "    df = df.reset_index(drop=True)\n",
    "    fires2raster(iop.dst, fires, data, region, keys=keys)\n",
    "    df.to_file(iop.dst/'banet_nrt.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: \n",
    "```python\n",
    "iop = InOutPath('outputs', 'web')\n",
    "R = Region.load('config/R_PT.json')\n",
    "filter_region = Polygon([[-10, 44], [-6, 44], [-6, 36], [-10, 36]])\n",
    "process_last(iop, R, filter_region)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_geo.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_models.ipynb.\n",
      "Converted 04_predict.ipynb.\n",
      "Converted 04b_nrt.ipynb.\n",
      "Converted 04c_historical.ipynb.\n",
      "Converted 05_train.ipynb.\n",
      "Converted 06_cli.ipynb.\n",
      "Converted 07_web.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted tutorial.australia2020.ipynb.\n",
      "Converted tutorial.australia2020_100m.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fastai_dev)",
   "language": "python",
   "name": "fastai_dev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
